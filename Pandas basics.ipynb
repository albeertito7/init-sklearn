{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas basics\n",
    "\n",
    "Pandas is a software library written as an extension to NumPy for high-level data manipulation and analysis. In particular, it provides data structures and operations for manipulating numerical tables and time series.\n",
    "\n",
    "Its key data structure is called the `DataFrame` that allows you to store and manipulate tabular data in rows of observations and columns of variables.\n",
    "\n",
    "Open source software, distributed under a liberal BSD license, Pandas is developed and maintained publicly on GitHub by a vibrant, responsive, and diverse community.\n",
    "\n",
    "- **Author:** Wes McKinney\n",
    "- **Creation year:** 2008\n",
    "- **Last stable version:** 1.2.1\n",
    "- **Programmed in:** Python\n",
    "- **Programming languages:** Python, C, CPython\n",
    "- **License:** BSD (Berkeley Software Distribution)\n",
    "- **Requires:** numpy, pytz, python-dateutil\n",
    "- **Code base:** https://github.com/pandas-dev/pandas\n",
    "- **Home-page:** https://pandas.pydata.org\n",
    "\n",
    "\n",
    "### Why use Pandas?\n",
    "\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
    "\n",
    "Pandas can clean messy data sets, and make them readable and relevant.\n",
    "\n",
    "Relevant data is very important in data science.\n",
    "\n",
    "> **Data Science:** is a branch of computer science where is studied how to store, use and analyze data for deriving information from it.\n",
    "\n",
    "### What can Pandas do?\n",
    "\n",
    "Pandas gives you answers about the data like:\n",
    "\n",
    "- Is there a correlation between two or more columns?\n",
    "- What is average value?\n",
    "- Max value?\n",
    "- Min value?\n",
    "\n",
    "Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called **cleaning the data**.\n",
    "\n",
    "\n",
    "### Why Pandas is build on Numpy?\n",
    "\n",
    "Numpy is highly efficient when working with large arrays, but they are pure arrays, with no metadata related to them.\n",
    "\n",
    "We (*with a true engineer spirit*) want to not only work fast but also comfortably. Imagine that we load a dataset with features (i.e. columns) such as \"sex\", \"age\", \"city\"...\n",
    "When we have to get the city of a specific observation (i.e. row) we have to remember that \"city\" is the third column (in programming language the index 2).\n",
    "\n",
    "Imagine if we could add some metadata to an array, so that when we want to access any column we can do it with readable names instead of indexes.\n",
    "\n",
    "That's the reason why Pandas was developed, to provide an **abstraction layer** because is build on top of Numpy.\n",
    "\n",
    "\n",
    "## Get Started\n",
    "\n",
    "**To install python is used 'pip' as package manager but there are others like 'anaconda' that can be used as well**\n",
    "\n",
    "We can check if the pandas python module is installed, just running the next command in our shell. If so, it will show us information about it along with the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not have it installed, we can install it using the following command in our shell (usually inside a virtualenv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if the version installed is not the most recent one; we can update the module by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step\n",
    "\n",
    "First we need to import the module to give it access to the python script, and renaming it using the most common convention -> **pd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses the concept of `Series` to represent single-dimensional data, and `DataFrame` for data with multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Single dimension:\\n\")\n",
    "print(pd.Series([1, 2, 3, 4]))\n",
    "\n",
    "print(\"\\n\\nTwo dimensions:\\n\")\n",
    "print(pd.DataFrame([[1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the data has \"names\" for the rows and the columns (numbers in this case). But this is no different from what we were doing using numpy. So let's name our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "pd.DataFrame(data, columns=[\"c1\", \"c2\", \"c3\"], index=[\"user 1\", \"user 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even can create them from dictionaries! In this case, it will fetch the names from the dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"c1\": [1, 4],\n",
    "    \"c2\": [2, 5],\n",
    "    \"c55\": [3, 6]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even set values to be other types, such as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    \"c1\": [\"a\", \"b\", \"c\"],\n",
    "    \"c2\": [1, 2, 3],\n",
    "    \"c3\": [1., 2., 3.]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing values\n",
    "Let's see how to access the values of the dataframe.\n",
    "\n",
    "First, let's fetch a column with its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"c1\": [1, 4],\n",
    "    \"c2\": [2, 5],\n",
    "    \"c55\": [3, 6]\n",
    "}\n",
    "\n",
    "dataframe = pd.DataFrame(data, index=[\"user 1\", \"user 2\"])\n",
    "\n",
    "dataframe[\"c2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access a single value using the `loc` \"function\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[\"user 1\", \"c2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to use numeric indexing instead of the label? For those cases, pandas provides us with the \"function\" `.iloc`, that behaves like `.loc` but using integers as indexes, instead of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing multiple columns\n",
    "\n",
    "Imagine we have the following dataset (pandas allows us to read files from an URL directly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv')\n",
    "print(iris.shape)  # same meaning as numpy\n",
    "iris.head()  # print only the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how we would fetch a single column, but what about fetching the columns \"sepal_length\" and \"sepal_width\"? In those cases, instead of using a single label, we could use a list of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[[\"sepal_length\", \"sepal_width\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is also a dataframe, with all the rows but only the columns we selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows\n",
    "\n",
    "Finally, we also might want to get only a subset of the rows. For example, in the iris dataset we would like to get all the rows that are from a specific type. In this case, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris[iris[\"species\"] == \"virginica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this into two steps:\n",
    "\n",
    "- Checking which rows are passing our check\n",
    "- Filter the dataset with a list/pandas.Series of True/False values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = iris[\"species\"] == \"virginica\"\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When filtering by rows, the iterable we use in the \"second step\" must have the same amount of rows as the dataframe, otherwise it will return a ValueError, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iris[[True, False, False]] # <-- error\n",
    "iris[[False] * 10 + [True] * 140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using as indices a True/False iterable, we can use different conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris[\"sepal_length\"] < 4.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even combine multiple conditions. In those cases though, remember that we are applying boolean operations on the dataframes.\n",
    "\n",
    "From pandas documentation:\n",
    ">Another common operation is the use of boolean vectors to filter the data. The operators are: | for or, & for and, and ~ for not. These must be grouped by using parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[(iris[\"sepal_length\"] < 4.5) & (iris[\"sepal_width\"] < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Numpy\n",
    "Usually, we would load our data using pandas, and do our preprocessing with their high-level methods to prepare the data. Then, we can either convert it to a numpy array using `dataframe.values` or feed it directly to some libraries that work with both types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataframe.values))\n",
    "print(dataframe.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
