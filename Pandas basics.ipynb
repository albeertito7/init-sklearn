{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas basics\n",
    "\n",
    "Pandas is a software library written as an extension to NumPy for high-level data manipulation and analysis. In particular, it provides data structures and operations for manipulating numerical tables and time series.\n",
    "\n",
    "Its key *data structure* is called the `DataFrame` that allows you to store and manipulate tabular data in rows of observations and columns of variables.\n",
    "\n",
    "Open source software, distributed under a liberal BSD license, Pandas is developed and maintained publicly on GitHub by a vibrant, responsive, and diverse community.\n",
    "\n",
    "- **Author:** Wes McKinney\n",
    "- **Creation year:** 2008\n",
    "- **Last stable version:** 1.2.1\n",
    "- **Programmed in:** Python\n",
    "- **Programming languages:** Python, C, CPython\n",
    "- **License:** BSD (Berkeley Software Distribution)\n",
    "- **Requires:** numpy, pytz, python-dateutil\n",
    "- **Code base:** https://github.com/pandas-dev/pandas\n",
    "- **Home-page:** https://pandas.pydata.org\n",
    "\n",
    "\n",
    "### Why use Pandas?\n",
    "\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
    "\n",
    "Pandas can clean messy data sets, and make them readable and relevant.\n",
    "\n",
    "Relevant data is very important in data science.\n",
    "\n",
    "> **Data Science**: is a branch of computer science where is studied how to store, use and analyze data for deriving information from it.\n",
    "\n",
    "### What can Pandas do?\n",
    "\n",
    "Pandas gives you answers about the data like:\n",
    "\n",
    "- Is there a correlation between two or more columns?\n",
    "- What is average value?\n",
    "- Max value?\n",
    "- Min value?\n",
    "\n",
    "Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called **cleaning the data**.\n",
    "\n",
    "\n",
    "### Why Pandas is build on Numpy?\n",
    "\n",
    "Numpy is highly efficient when working with large arrays, but they are pure arrays, with no metadata related to them.\n",
    "\n",
    "We (*with a true engineer spirit*) want to not only work fast but also comfortably. Imagine that we load a dataset with features (i.e. columns) such as \"sex\", \"age\", \"city\"...\n",
    "When we have to get the city of a specific observation (i.e. row) we have to remember that \"city\" is the third column (in programming language the index 2).\n",
    "\n",
    "Imagine if we could add some metadata to an array, so that when we want to access any column we can do it with readable names instead of indexes.\n",
    "\n",
    "That's the reason why Pandas was developed, to provide an **abstraction layer** because is build on top of Numpy.\n",
    "\n",
    "\n",
    "## Get Started\n",
    "\n",
    "> **Note**: for the installation is used *pip* as package manager but there are others like *anaconda* that can be used as well\n",
    "\n",
    "We can check if the **Pandas python module** is installed, just running the next command in our shell. If so, it will show us information about it along with the version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not have it installed, we can install it using the following command in our shell (usually inside a virtualenv):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if the version installed is not the most recent one; we can update the module by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step\n",
    "\n",
    "First we need to import the module to give it access to the python script, and renaming it to \"**pd**\" following the most common convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses the concept of `Series` to represent single-dimensional data, and `DataFrame` for data with multiple dimensions.\n",
    "\n",
    "> **DataFrame**: a 2-dimensional data structure that can store data of different types (including characters, integers, floating point values, categorical data and more) in columns. It is similar to a spreadsheet, a SQL table or the data.frame in R.\n",
    "\n",
    "> **Series**: each column in a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Single dimension:\\n\")\n",
    "print(pd.Series([1, 2, 3, 4]))\n",
    "\n",
    "print(\"\\n\\nTwo dimensions:\\n\")\n",
    "print(pd.DataFrame([[1, 2, 3], [4, 5, 6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the data has \"labels\" for the rows and the columns (indexes by default if not set). But this is no different from what we were doing using numpy.\n",
    "\n",
    "> **Note**: a pandas `Series` has no column labels, as it is just a single column of a `DataFrame`. A `Series` does have row labels.\n",
    "\n",
    "So let's label our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "pd.DataFrame(data, columns=[\"c1\", \"c2\", \"c3\"], index=[\"user 1\", \"user 2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even create them from dictionaries! In this case, it will fetch the column labels from the dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"c1\": [1, 4],\n",
    "    \"c2\": [2, 5],\n",
    "    \"c55\": [3, 6]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we can set values to be other types, such as strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    \"c1\": [\"a\", \"b\", \"c\"],\n",
    "    \"c2\": [1, 2, 3],\n",
    "    \"c3\": [1., 2., 3.]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing values\n",
    "Let's see how to access the values of the `Dataframe`.\n",
    "\n",
    "First, let's fetch a column with its label:\n",
    "\n",
    "> **Note**: if you are familiar to `Python dictionaries`, the selection of a single column is similar to select dictionary values based on the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user 1    2\n",
       "user 2    5\n",
       "Name: c2, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"c1\": [1, 4],\n",
    "    \"c2\": [2, 5],\n",
    "    \"c55\": [3, 6]\n",
    "}\n",
    "\n",
    "dataframe = pd.DataFrame(data, index=[\"user 1\", \"user 2\"])\n",
    "dataframe[\"c2\"] # to select the column, use the column label in between square brackets []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When selecting a single column of a pandas `DataFrame`, the result is a pandas `Series`. We can verify this by checking the type of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataframe[\"c2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access a single value using the `loc` \"function\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[\"user 1\", \"c2\"] # [row label, column label] # only string values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### What if we want to use numeric indexing instead of the label?\n",
    "\n",
    "For those cases, pandas provides us with the \"function\" `.iloc`, that behaves like `.loc` but using integers as indexes, instead of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.iloc[0, 1] # only numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing multiple columns\n",
    "\n",
    "Imagine we have the following *dataset* (pandas allows us to read files from an URL directly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv') # .read_csv returns a DataFrame\n",
    "print(iris.shape)  # same meaning as numpy # (rows, columns)\n",
    "iris.head()  # method to print only the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen how we would fetch a single column, but what about fetching the columns \"*sepal_length*\" and \"*sepal_width*\"? In those cases, instead of using a single label, we could use a list of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width\n",
       "0           5.1          3.5\n",
       "1           4.9          3.0\n",
       "2           4.7          3.2\n",
       "3           4.6          3.1\n",
       "4           5.0          3.6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[[\"sepal_length\", \"sepal_width\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are doing a multiple column selection, the result is also a `DataFrame` with all the rows but only the columnsselected.\n",
    "\n",
    "> **Note**: the inner square brackets define a `Python list` with column labels, whereas the outer brackets are used to select the data from a pandas `DataFrame` as seen in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows\n",
    "\n",
    "Finally, we also might want to get only a subset of the rows. For example, in the *iris dataset* we would like to get all the rows that are from a specific type.\n",
    "\n",
    "In this case, we would do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris[\"species\"] == \"virginica\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this into two steps:\n",
    "\n",
    "- Checking which rows are passing our check/condition returning a `Series` of True/False values.\n",
    "- Filter the `DataFrame` thanks to the `Series` got in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = iris[\"species\"] == \"virginica\" # get a True/False Series, checking the condition for each row/record\n",
    "indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris[indices] # filtering the DataFrame from the True/False values got"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When filtering by rows, the iterable we use in the \"second step\" must have the same amount of rows as the `Dataframe`, otherwise it will return a `ValueError`, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iris[[True, False, False]] # <-- error\n",
    "iris[[False] * 10 + [True] * 140] # ValueError: Item wrong length 149 instead of 150 # change 139 to 140 to fix it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using as indexes a True/False iterable, we can use different conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[iris[\"sepal_length\"] < 4.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even combine multiple conditions. In those cases though, remember that we are applying boolean operations on the dataframes.\n",
    "\n",
    "From pandas documentation:\n",
    "> Another common operation is the use of boolean vectors to filter the data. The operators are: | for or, & for and, and ~ for not. These must be grouped by using parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris[(iris[\"sepal_length\"] < 4.5) & (iris[\"sepal_width\"] < 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and Numpy\n",
    "Usually, we would load our data using pandas, and do our preprocessing with their high-level methods to prepare the data. Then, we can either convert it to a numpy array using `dataframe.values` or feed it directly to some libraries that work with both types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataframe.values))\n",
    "print(dataframe.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
